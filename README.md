Telecom X - Predicci√≥n de Churn (Parte 2) üìä
1. Prop√≥sito del An√°lisis
El objetivo principal de este proyecto es desarrollar un modelo de machine learning capaz de predecir la probabilidad de que un cliente cancele su servicio (churn) con la empresa de telecomunicaciones Telecom X. Al identificar los factores m√°s influyentes y los perfiles de clientes con mayor riesgo, la empresa puede dise√±ar estrategias de retenci√≥n proactivas y personalizadas, optimizando recursos y minimizando la p√©rdida de ingresos.

2. Estructura del Proyecto
El repositorio est√° organizado de la siguiente manera para facilitar la navegaci√≥n y reproducibilidad del an√°lisis:

telecom-churn-prediction/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ telecom_data_tratado.csv    # Dataset limpio y preprocesado
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01_analisis_churn.ipynb     # Cuaderno principal con todo el an√°lisis
‚îÇ
‚îú‚îÄ‚îÄ visualizations/
‚îÇ   ‚îî‚îÄ‚îÄ churn_por_contrato.png      # Ejemplo de visualizaci√≥n guardada
‚îÇ   ‚îî‚îÄ‚îÄ importancia_variables.png   # Ejemplo de visualizaci√≥n guardada
‚îÇ
‚îî‚îÄ‚îÄ README.md                       # Este archivo
/data: Contiene el dataset tratado y listo para ser cargado por el notebook.

/notebooks: Alberga el cuaderno de Jupyter (.ipynb) con todo el c√≥digo del an√°lisis, desde la carga de datos hasta la evaluaci√≥n de modelos.

/visualizations: Carpeta opcional para guardar los gr√°ficos m√°s relevantes generados durante el an√°lisis.

3. Proceso de Preparaci√≥n de Datos
La preparaci√≥n de los datos fue una etapa crucial para asegurar el rendimiento y la validez de los modelos.

Clasificaci√≥n de Variables:

Num√©ricas: tenure, MonthlyCharges, TotalCharges.

Categ√≥ricas: gender, SeniorCitizen, Partner, Dependents, Contract, PaymentMethod, InternetService, entre otras.

Codificaci√≥n y Normalizaci√≥n:

One-Hot Encoding: Se aplic√≥ a todas las variables categ√≥ricas para convertirlas en un formato num√©rico que los modelos puedan procesar, evitando la creaci√≥n de un orden jer√°rquico artificial.

Normalizaci√≥n (StandardScaler): Se escalaron las variables num√©ricas para modelos sensibles a la escala, como la Regresi√≥n Log√≠stica. Esto asegura que ninguna variable domine a otra solo por tener una magnitud mayor.

Separaci√≥n de Datos:

El conjunto de datos se dividi√≥ en 80% para entrenamiento y 20% para prueba. Se utiliz√≥ una divisi√≥n estratificada por la variable objetivo (Churn) para mantener la proporci√≥n de clases en ambos conjuntos.

Justificaci√≥n de Decisiones:

Se eligi√≥ la Regresi√≥n Log√≠stica por su alta interpretabilidad, permitiendo entender el impacto de cada variable en la probabilidad de churn.

Se seleccion√≥ Random Forest como un modelo m√°s complejo y robusto, que no requiere normalizaci√≥n de datos y es capaz de capturar relaciones no lineales.

Se aplic√≥ la t√©cnica SMOTE en el conjunto de entrenamiento para corregir el desbalance de clases, lo que ayuda a que el modelo no se incline a predecir √∫nicamente la clase mayoritaria (no churn).

4. An√°lisis Exploratorio de Datos (EDA) - Insights
Durante el EDA, se generaron varias visualizaciones para entender la relaci√≥n entre las variables y la cancelaci√≥n.

Insight 1: El tipo de contrato es el factor m√°s decisivo.

Los clientes con contratos mes a mes tienen una tasa de cancelaci√≥n dr√°sticamente mayor en comparaci√≥n con aquellos con contratos anuales. Esto sugiere una falta de lealtad y un alto riesgo.

(Ejemplo de gr√°fico a incluir: churn_por_contrato.png)

Insight 2: Los clientes nuevos son los m√°s propensos a cancelar.

La tasa de churn es muy alta durante los primeros meses de servicio y disminuye a medida que aumenta la antig√ºedad (tenure) del cliente. La retenci√≥n debe enfocarse en las etapas tempranas del ciclo de vida del cliente.

(Ejemplo de gr√°fico a incluir: un histograma de tenure separado por Churn)

5. Instrucciones para Ejecutar el Cuaderno
Para replicar este an√°lisis, sigue los siguientes pasos:

Clona o descarga este repositorio.

Aseg√∫rate de tener Python 3 instalado. Luego, instala las bibliotecas necesarias ejecutando el siguiente comando en tu terminal:

Bash

pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn jupyter
Inicia Jupyter Notebook:

Bash

jupyter notebook
Abre el cuaderno ubicado en la carpeta notebooks/01_analisis_churn.ipynb.

Carga los datos tratados. El cuaderno est√° configurado para cargar el archivo telecom_data_tratado.csv desde la carpeta /data. Aseg√∫rate de que la ruta sea correcta:

Python

# Ejemplo de c√≥digo dentro del notebook para cargar los datos
import pandas as pd
df = pd.read_csv('../data/telecom_data_tratado.csv')
Ejecuta las celdas en orden para reproducir todo el an√°lisis. 
